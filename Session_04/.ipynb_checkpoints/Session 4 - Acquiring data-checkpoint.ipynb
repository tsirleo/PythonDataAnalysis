{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4 - Acquiring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session agenda\n",
    "1. How data is stored.\n",
    "2. Basic file formats: csv, json, hdf5.\n",
    "3. Working with different formats in Python.\n",
    "4. Text encodings, Pythonâ€™s standard library codecs module. Encoding and decoding data.\n",
    "5. Where to get data: data repositories (UCI Machine Learning Repository, sklearn datasets and other). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion - how data is stored?\n",
    "Let us discuss this point:\n",
    "1. What is important we talk about storing data?\n",
    "2. What features of data affect its storage?\n",
    "3. Why there is no universal data storage format?\n",
    "4. Give examples when data storage format can affect significantly the performed task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic file formats\n",
    "I am sure you have encountered a significant number of data storing formats. Let us just review a couple of them.\n",
    "\n",
    "### Comma-separated values (CSV)\n",
    "It is the most popular way to store tabular data. Instead of comma any other separator can be used (e.g. tab, white space, dot, colon and etc.).\n",
    "\n",
    "Reference:\n",
    "1. https://en.wikipedia.org/wiki/Comma-separated_values\n",
    "\n",
    "### JavaScript Object Notation (JSON)\n",
    "A very popular format for representing data in a form of attribute-value pairs. Commonly used for transmitting data objects in the course of browser/server communication. It can also be used to store hierarchical data.\n",
    "\n",
    "Let us check an example:\n",
    "```json\n",
    "{\n",
    "  \"firstName\": \"John\",\n",
    "  \"lastName\": \"Smith\",\n",
    "  \"isAlive\": true,\n",
    "  \"age\": 25,\n",
    "  \"address\": {\n",
    "    \"streetAddress\": \"21 2nd Street\",\n",
    "    \"city\": \"New York\",\n",
    "    \"state\": \"NY\",\n",
    "    \"postalCode\": \"10021-3100\"\n",
    "  },\n",
    "  \"phoneNumbers\": [\n",
    "    {\n",
    "      \"type\": \"home\",\n",
    "      \"number\": \"212 555-1234\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"office\",\n",
    "      \"number\": \"646 555-4567\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"mobile\",\n",
    "      \"number\": \"123 456-7890\"\n",
    "    }\n",
    "  ],\n",
    "  \"children\": [],\n",
    "  \"spouse\": null\n",
    "}\n",
    "```\n",
    "\n",
    "Python has a module for working with JSON data format in the standart library (json). \n",
    "\n",
    "Reference:\n",
    "1. https://en.wikipedia.org/wiki/JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#Encoding\n",
    "a = ['foo', {'bar': ('baz', None, 1.0, 2)}]\n",
    "print(type(a), type(a[1]))\n",
    "print(a)\n",
    "print(json.dumps(a))\n",
    "print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n",
    "{\"a\": 0, \"b\": 0, \"c\": 0}\n",
    "print(json.dumps([1,2,3,{'4': 5, '6': 7}], separators=(',', ':')))\n",
    "print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n",
    "\n",
    "#Decoding\n",
    "b = json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]')\n",
    "print(b)\n",
    "print(type(b),type(b[1]))\n",
    "\n",
    "#Streaming API\n",
    "from io import StringIO\n",
    "io = StringIO()\n",
    "json.dump(['streaming API'], io)\n",
    "print(io.getvalue())\n",
    "\n",
    "io = StringIO('[\"streaming API\"]')\n",
    "print(json.load(io))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding and decoding data\n",
    "When working with data, which is send of the internet, you might need to encode or decode it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json, urllib.request\n",
    "\n",
    "url = \"http://mks2.cs.msu.ru/\"\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    encoded = response.read()\n",
    "    print(encoded)\n",
    "    response_encoding = response.headers.get_content_charset('charset')\n",
    "    print('After decoding:\\n')\n",
    "    decoded = encoded.decode(encoding = response_encoding)\n",
    "    print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Data Format (HDF)\n",
    "Hierarchical Data Format (HDF) is a set of file formats (HDF4, HDF5) designed to store and organize large amounts of data. Originally developed at the National Center for Supercomputing Applications, it is supported by The HDF Group, a non-profit corporation whose mission is to ensure continued development of HDF5 technologies and the continued accessibility of data stored in HDF.\n",
    "\n",
    "The current version, HDF5, differs significantly in design and API from the major legacy version HDF4. HDF5 simplifies the file structure to include only two major types of object:\n",
    "\n",
    "* Datasets, which are multidimensional arrays of a homogeneous type\n",
    "* Groups, which are container structures which can hold datasets and other groups\n",
    "\n",
    "To use HDF files with Python usually additional packages are needed (a number of formats were created on the basis of HDF5 format and usually need specific libraries to handle them).\n",
    "\n",
    "We will be using http://unidata.github.io/netcdf4-python/ for our next example. Let us explore \".CDF\" files from the \"Data/LS_MS Data CDF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to get data\n",
    "There are numerous ways to get data. Let us discuss the most typical cases:\n",
    "\n",
    "1. Raw data - data collected from an experiment, survey, automated monitoring of a certain process and etc.\n",
    "2. Data repositories - web-sites, which contains preprocessed data, which is stored in typical data storage formats and can be used for data analysis.\n",
    "  1. UCI Machine learning repository (http://archive.ics.uci.edu/ml/index.html)\n",
    "  2. kaggle (https://www.kaggle.com/datasets)\n",
    "  3. scikit-learn datasets (http://scikit-learn.org/stable/datasets/)\n",
    "  3. Field or application specific repositories - just check the web - you will find a lot of different options\n",
    "\n",
    "3. Databases - relational (SQL) and non-relational (NoSQL) databases.\n",
    "\n",
    "We can use iPython notebook to load data directly from the repository. Check the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "iris = pd.read_csv(url, names=names)\n",
    "iris.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
